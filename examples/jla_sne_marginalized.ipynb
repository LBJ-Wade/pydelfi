{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interpolate\n",
    "import simulators.jla_supernovae.jla_simulator as jla\n",
    "import pydelfi.ndes as ndes\n",
    "import pydelfi.delfi as delfi\n",
    "import pydelfi.score as score\n",
    "import pydelfi.priors as priors\n",
    "import tensorflow as tf\n",
    "from scipy.linalg import block_diag\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the prior\n",
    "In this case, we need to set up priors over interesting and nuisance parameters. The nuisance parameter prior could be conditional on the interesting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([0, -1.5])\n",
    "upper = np.array([0.6, 0])\n",
    "prior = tfd.Blockwise([tfd.Uniform(low=lower[i], high=upper[i]) for i in range(2)])\n",
    "\n",
    "eta_lower = np.array([-20, 0, 0, -0.5])\n",
    "eta_upper = np.array([-18, 1, 6, 0.5])\n",
    "eta_prior = tfd.Blockwise([tfd.Uniform(low=eta_lower[i], high=eta_upper[i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the simulator\n",
    "This must have the signature `simulator(parameters, seed, args, batch)` -> `np.array([batch, ndata])`\n",
    "\n",
    "Note: In this case since we are going to infer the nuisance parameter marginalized posterior directly, the simulator takes in interesting parameters only, and draws nuisance parameters from their prior _as part of the simulation process_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLASimulator = jla.JLA_Model()\n",
    "\n",
    "def simulator(theta, seed, simulator_args, batch):\n",
    "    \n",
    "    eta_prior = simulator_args[0]\n",
    "    eta = eta_prior.sample().numpy()\n",
    "    \n",
    "    return JLASimulator.simulation(np.concatenate([theta, eta]), seed)\n",
    "\n",
    "simulator_args = [eta_prior]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the compressor\n",
    "This must have the signature `compressor(data, args)` -> `np.array([n_summaries])`\n",
    "In this case we are going to do _nuisance hardened_ Gaussian score compression $$\\bar{\\mathbf{t}}_\\theta = \\mathbf{t}_\\theta - \\mathbf{F}_{\\theta\\eta}\\mathbf{F}^{-1}_{\\eta\\eta}\\mathbf{t}_\\eta$$ where $$\\mathbf{t}_{(\\theta, \\eta)} = \\nabla_{(\\theta, \\eta)}^T\\boldsymbol\\mu_*\\mathbf{C}^{-1}(\\mathbf{d}-\\boldsymbol\\mu_*)$$\n",
    "We'll use the class `score.Gaussian`. For this we'll need some fiducial parameters, the mean its derivative at the fiducial parameters, the inverse covariance, and the inverse Fisher matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_fiducial = np.array([0.2, -0.75])\n",
    "eta_fiducial = np.array([-19.04, 0.125, 2.64, -0.05])\n",
    "\n",
    "mu = JLASimulator.apparent_magnitude(np.concatenate([theta_fiducial, eta_fiducial]))\n",
    "Cinv = JLASimulator.Cinv\n",
    "\n",
    "h = np.array(abs(np.concatenate([theta_fiducial, eta_fiducial])))*0.01\n",
    "dmudt = JLASimulator.dmudt(np.concatenate([theta_fiducial, eta_fiducial]), h)\n",
    "\n",
    "Compressor = score.Gaussian(len(JLASimulator.data), np.concatenate([theta_fiducial, eta_fiducial]), \n",
    "                            mu = mu, Cinv = Cinv, dmudt = dmudt)\n",
    "Compressor.compute_fisher()\n",
    "Finv = Compressor.Finv[0:2,0:2]\n",
    "\n",
    "nuisance_indices = np.arange(2,6)\n",
    "\n",
    "def compressor(d, compressor_args):\n",
    "    nuisances_indices = compressor_args[0]\n",
    "    return Compressor.projected_scoreMLE(d, nuisance_indices)\n",
    "compressor_args = [nuisance_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress the JLA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_data = compressor(JLASimulator.data, compressor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create endemble of NDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDEs = [ndes.ConditionalMaskedAutoregressiveFlow(\n",
    "            n_parameters=6,\n",
    "            n_data=6,\n",
    "            n_mades=5,\n",
    "            n_hidden=[30,30], \n",
    "            activation=tf.keras.layers.LeakyReLU(0.01),\n",
    "            kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-5, seed=None),\n",
    "            all_layers=True)]\n",
    "\n",
    "NDEs += [ndes.MixtureDensityNetwork(\n",
    "            n_parameters=6,\n",
    "            n_data=6, \n",
    "            n_components=i+1,\n",
    "            n_hidden=[30], \n",
    "            activation=tf.keras.layers.LeakyReLU(0.01))\n",
    "        for i in range(5)]\n",
    "\n",
    "NDEs += [ndes.SinhArcSinhMADE(\n",
    "            n_parameters=6,\n",
    "            n_data=6,\n",
    "            n_hidden=[64],\n",
    "            activation=tf.tanh,\n",
    "            kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-5, seed=None),\n",
    "            bias_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-5, seed=None)\n",
    "        )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DELFI object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble = delfi.Delfi(compressed_data, prior, NDEs, \n",
    "                            Finv=Finv, \n",
    "                            theta_fiducial=theta_fiducial, \n",
    "                            param_names=['\\\\Omega_m', 'w_0', 'M_\\mathrm{B}', '\\\\alpha', '\\\\beta', '\\\\delta M'], \n",
    "                            results_dir=\"simulators/jla_supernovae/results_marginal\",\n",
    "                            filename=\"jla\",\n",
    "                            optimiser=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "                            optimiser_arguments=None,\n",
    "                            dtype=tf.float32,\n",
    "                            posterior_chain_length=200,\n",
    "                            nwalkers=500,\n",
    "                            input_normalization=\"fisher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher pre-training to initialize the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.fisher_pretraining(n_batch=5000, epochs=1000, patience=20, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Neural Likeihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_initial = 100\n",
    "n_batch = 100\n",
    "n_populations = 11\n",
    "\n",
    "DelfiEnsemble.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=10, simulator_args=simulator_args, compressor_args=compressor_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
